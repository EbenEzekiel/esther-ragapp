Course: ADSC 3910 ‚Äì Applied Data Science Integrated Practice 2

Instructor: Dr. Quan Nguyen

Institution: Thompson Rivers University

Term: Fall 2025

## Team

| Member | Role | GitHub Handle |
|--------|------|---------------|
| Abikoye Esther | Vector Store & Data Ingestion; Query transformation & Retrieval | @EstherAbik |
| Sahaya Vinish | Prompt Engineering; Documentation; Slide preparation | @Vinish99 |

Overview
--------
This project implements **Retrieval-Augmented Generation (RAG)** pipeline that retrieves course-specific materials from a MongoDB Atlas vector store and uses an OpenAI model to generate context-aware answers. The system leverages multi-query transformations and RAG-fusion to enhance retrieval,and employs LangChain  with LLM integration for seamless response generation.Together, these components enable intelligent book recommendations and question answering that are both precise and contextually relevant. The end product of this project is a streamlit app that recommends books based on user query

![Python](https://img.shields.io/badge/python-3.12+-blue.svg)
![Streamlit](https://img.shields.io/badge/streamlit-1.28+-red.svg)
![LangChain](https://img.shields.io/badge/langchain-latest-green.svg)

Key features
- Query transformation for higher-quality retrieval  
- External prompt files (`prompts/`) for maintainability  
- Conda-based environment reproducibility  
- LangSmith traces for debugging and transparency
- Streamlit app in `rag_app/` and supporting notebooks for exploration



## Repository Structure
```
Group-1/
‚îú‚îÄ‚îÄ .env.example                          # Template for environment variables                                
‚îú‚îÄ‚îÄ README.md                             
‚îú‚îÄ‚îÄ environment.yml                       # environment specification
‚îú‚îÄ‚îÄ logs/                                 # LangSmith trace logs
‚îÇ   ‚îî‚îÄ‚îÄ trace_2025-11-19.json
‚îú‚îÄ‚îÄ notebooks/                            # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ Project.ipynb      
‚îÇ   ‚îî‚îÄ‚îÄ rag.ipynb                         # RAG pipeline 
‚îú‚îÄ‚îÄ prompts/                              # Prompt templates
‚îÇ   ‚îú‚îÄ‚îÄ README.md                         # Prompts documentation
‚îÇ   ‚îú‚îÄ‚îÄ get_response_v1.txt               # Response template
‚îÇ   ‚îú‚îÄ‚îÄ multi_query_v1.txt                # Multi-query expansion
‚îÇ   ‚îî‚îÄ‚îÄ system_prompt_v1.txt              # System instructions
‚îú‚îÄ‚îÄ rag_app/                              # Streamlit RAG application
‚îÇ   ‚îú‚îÄ‚îÄ application.py                    # Core RAG logic
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                  # App dependencies
‚îî‚îÄ‚îÄ run_app.py
    
```
---

## Data Preparation

### Clone Repository
```bash
git clone https://github.com/TRU-PBADS/Group-1.git
cd Group-1
```

### 1Ô∏è‚É£ Acquire Dataset
Download the dataset from Kaggle: [Goodreads Book Reviews Dataset](https://www.kaggle.com/datasets/pypiahmad/goodreads-book-reviews1?select=goodreads_reviews_dedup.json)

**Collections used:**
- `reviews` - Book reviews data
- `books` - Book metadata
- `authors` - Author information

### 2Ô∏è‚É£ Filter Dataset
Restrict reviews to those with `date_started` in **August 2017** and match with corresponding books.

### 3Ô∏è‚É£ Configure MongoDB Credentials
Create a file named `credentials_mongodb.json` in the `notebooks/` directory with the following template:

```json
{
    "host": "your-mongodb-host",
    "username": "your-username",
    "password": "your-password"
}
```

‚ö†Ô∏è **Important:** Do not commit this file to GitHub. It is excluded via `.gitignore` for security.

### 4Ô∏è‚É£ Upload Data to MongoDB
Follow the data upload procedures outlined in `notebooks/Project.ipynb`.

### 5Ô∏è‚É£ Perform Schema Transformation
Schema transformation steps are detailed in `notebooks/Project.ipynb` (Step 4), use actual names you saved your files with

---

## ‚öôÔ∏è Environment Setup 

### 1Ô∏è‚É£ Create Conda Environment
```bash
conda env create -f environment.yml
conda activate rag-pipeline
```

### 2Ô∏è‚É£ Verify Python and Package Versions
```bash
python --version       # expected: 3.12.12
conda list langchain    # check version matches environment.yml
```

### 3Ô∏è‚É£ Set Up Environment Variables
Copy `.env.example` ‚Üí `.env` and fill in your own credentials:
```
OPENAI_API_KEY=sk-xxxx
MONGODB_URI=your_mongo_connection_uri
```

Ensure `.env` is **not** committed (`.gitignore` includes it).



## 4Ô∏è‚É£ Set up Streamlit secrets

Create a `.streamlit/secrets.toml` file with the following structure and **replace your API keys** accordingly:

```toml
[langsmith]
tracing = "true"
endpoint = "https://api.smith.langchain.com"
api_key = "your-langsmith-api-key"

[google]
api_key = "your-google-api-key"

[mongodb]
uri = "mongodb+srv://user1:user1@cluster0.lqirl.mongodb.net/?retryWrites=true&w=majority"
```
---

## üöÄ Running the Pipeline

### Launch Jupyter Notebooks
```bash
jupyter notebook notebooks/rag.ipynb
```

---

## üí¨ Example Query Walkthrough
**Query:**  
> ‚ÄúI'm looking for a book to help me improve my leadership skills and communicate more effectively at work‚Äù

**Under the hood:**
- Multi‚Äëquery transformation:
  - The original query is expanded into 4 semantically diverse sub‚Äëqueries, :
    - Question 1: Best books for improving leadership and communication skills
    - Question 2: Books on effective workplace communication and leadership development
    - Question 3: Top books for enhancing leadership and communication in a professional setting
    - Question 4: Recommended books for managers to improve communication and leadership abilities

- RAG‚ÄëFusion step:
  - Each sub‚Äëquery is sent to MongoDB Atlas Vector Search.
  - Top documents from each query are retrieved.
  - Results are fused (deduplicated, ranked) into a final set of top‚Äëk documents.

- Prompts combined:
  - system_prompt_v1
  - get_response_v1
  - multi_query_v1

- LLM:
  - gpt‚Äë4o‚Äëmini

- Trace logged:
  - logs/trace_2025-10-26.json

- Expected Output (excerpt):
  - "'Based on the context, "The Coaching Habit: Say Less, Ask More & Change the Way You Lead Forever" seems like an excellent fit for your needs. One review describes it as a "Great book on conversations: how to listen more and ask the right questions," which directly addresses improving communication skills. Its title also indicates a focus on changing how you lead...'"

---

### Run the Streamlit Application
```bash
cd rag_app
streamlit run application.py
```

Access the app at `http://localhost:8501`

---

## ü§ñ RAG Application Features

### Architecture
- **Frontend**: Streamlit with custom neobrutalist CSS styling
- **Vector Database**: MongoDB Atlas with vector search capabilities  
- **Embeddings**: SentenceTransformers (all-MiniLM-L6-v2, 384 dimensions)
- **LLM**: Google Gemini 2.5 Flash for response generation
- **Framework**: LangChain for RAG pipeline orchestration
- **Monitoring**: LangSmith for tracing and debugging

### Key Features
- üîç **Multi-Query Retrieval**: Expands user queries into multiple perspectives for better recall
- üéØ **RAG Fusion**: Re-ranks retrieved documents by frequency scoring
- üí¨ **Streaming Responses**: Real-time AI response generation
- üìä **Session Tracking**: Monitor conversation metrics in the sidebar
- üé® **Modern UI**: Bold, colorful design with custom CSS
- üîó **Context-Aware**: Maintains chat history for coherent conversations

### RAG Pipeline Workflow
1. **Query Transformation**: User query expanded into 4 semantically diverse sub-queries
2. **Vector Search**: Each sub-query retrieves relevant documents from MongoDB Atlas
3. **RAG Fusion**: Results are fused and re-ranked by document frequency
4. **Context Building**: Top documents formatted with book titles, reviews, and ratings
5. **LLM Generation**: Gemini AI generates response using retrieved context and chat history
6. **Streaming Output**: Response streamed back to user interface

### Customization Options

**Modify AI Personality**  
Edit prompt templates in `prompts/` directory:
- `system_prompt_v1.txt` - Define behavior and tone
- `get_response_v1.txt` - Response format and rules  
- `multi_query_v1.txt` - Query expansion instructions

**Adjust Vector Search**  
Configure retriever in `application.py`:
```python
vector_store = MongoDBAtlasVectorSearch(
    collection=collection,
    embedding=embeddings,
    index_name="realvector_index",
    relevance_score_fn="cosine"  # or "euclidean", "dotProduct"
)
```

**Change Styling**  
Modify custom CSS variables in `application.py` for colors and design.

### Monitoring & Debugging
- **LangSmith Tracing**: View all LLM calls, retrieval results, and performance metrics
- **Session Metrics**: Track message count and conversation flow in sidebar
- **Error Handling**: Graceful fallbacks for API failures and network issues

### Troubleshooting
- **Vector Search Issues**: Ensure index dimension matches embedding model (384 for all-MiniLM-L6-v2)
- **Connection Errors**: Verify MongoDB URI and API keys in `.streamlit/secrets.toml`
- **Slow Responses**: Check network latency, optimize retriever parameters, or use closer MongoDB region



## üßæ Prompts and Documentation
All prompts are stored and versioned under `/prompts`.

| File | Purpose | Version |
|------|----------|----------|
| `system_prompt_v1.txt` | Defines assistant behavior and tone | v1.0 |
| `get_response_v1.txt` | Template for user query + context insertion | v1.0 |
| `multi_query_v1.txt`. | Expands the original question into multiple newline‚Äëseparated queries to increase recall. | v1.0 |

Example loader:
```python
from utils import load_prompt
system_prompt = load_prompt(".../prompts/system_prompt_v1.txt")
human_prompt = load_prompt(".../prompts/get_response_v1.txt")
multi_query_prompt = load_prompt(".../prompts/multi_query_v1.txt")
```
See `prompts/README.md` for variable placeholders like `{query}` and `{context}`.


---

## üß≠ Reflection
**Challenges:** We encountered limitations with token capacity, which led us to adopt a more flexible model architecture without strict token restrictions.

**Next Steps:** Next up, we‚Äôll get the star rating feature working smoothly and make the app easier and more fun to use.

---

## üìö References & Acknowledgements
- TRU ADSC 3910 Course Materials  
- LangChain and LangSmith Documentation  
- MongoDB Atlas Vector Search Guides  
- OpenAI API Docs  

---



